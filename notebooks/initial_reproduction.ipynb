{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF25NSM2jQxv"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omk-SitljQx0"
      },
      "outputs": [],
      "source": [
        "%cd -q .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrwcspd8jQx2",
        "outputId": "1e115eea-7205-4e8d-884d-9a35e1ffe9f8"
      },
      "outputs": [],
      "source": [
        "import lcpfn\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dhkhXEvjQx3"
      },
      "source": [
        "# Training the LCPFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "_nHnLBlNjQx5",
        "outputId": "2778df34-4cdf-429c-d40f-cb503fbf2e87"
      },
      "outputs": [],
      "source": [
        "%pip install torch==1.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt2BrGFbjQx7",
        "outputId": "776f3d41-55fb-487d-a30d-8d76a49a0834"
      },
      "outputs": [],
      "source": [
        "get_batch_func = lcpfn.create_get_batch_func(prior=lcpfn.sample_from_prior)\n",
        "\n",
        "# They tried\n",
        "# emsize ∈ [128, 256, 512]\n",
        "# nlayers ∈ [3, 6, 12]\n",
        "# nb_data ∈ [100k, 1M, 10M]\n",
        "# steps_per_epoch is hardcoded to 100\n",
        "# num_epochs?\n",
        "\n",
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch_func,\n",
        "                          seq_len=100,\n",
        "                         emsize=256,\n",
        "                         nlayers=3,\n",
        "                         num_borders=1000,\n",
        "                         lr=0.001,\n",
        "                         batch_size=500,\n",
        "                         epochs=300)\n",
        "\n",
        "transformer_model = result[2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPNYY6hNjQx8"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"lcpfn/trained_models/\"+\"reproduction_model.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e8WB2zQjQx9"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "\n",
        "torch.save(transformer_model, model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkMiFLOjQx-"
      },
      "source": [
        "# Getting the lc data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv8ESnYE4uvI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Get the data for cutoff 10 inference\n",
        "prior_10 = lcpfn.sample_from_prior(np.random)\n",
        "curve_10, _ = prior_10()\n",
        "x_10 = torch.arange(1, 101).unsqueeze(1)\n",
        "y_10 = torch.from_numpy(curve_10).float().unsqueeze(1)\n",
        "cutoff_10 = 10\n",
        "data_10 = {'x': x_10, 'y': y_10, 'cutoff': cutoff_10}\n",
        "\n",
        "# Get the data for cutoff 20 inference\n",
        "prior_20 = lcpfn.sample_from_prior(np.random)\n",
        "curve_20, _ = prior_20()\n",
        "x_20 = torch.arange(1, 101).unsqueeze(1)\n",
        "y_20 = torch.from_numpy(curve_20).float().unsqueeze(1)\n",
        "cutoff_20 = 20\n",
        "data_20 = {'x': x_20, 'y': y_20, 'cutoff': cutoff_20}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9caSWD1jQyC"
      },
      "source": [
        "# Inference with LCPFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vbdzaax5ptK"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "lcpfn_model = lcpfn.LCPFN(model_save_path)\n",
        "\n",
        "# Predictions for cutoff = 10\n",
        "x = data_10['x']\n",
        "y = data_10['y']\n",
        "cutoff = data_10['cutoff']\n",
        "predictions_10 = lcpfn_model.predict_quantiles(x_train=x[:cutoff], y_train=y[:cutoff], x_test=x[cutoff:], qs=[0.05, 0.5, 0.95])\n",
        "\n",
        "# Predictions for cutoff = 20\n",
        "x = data_20['x']\n",
        "y = data_20['y']\n",
        "cutoff = data_20['cutoff']\n",
        "predictions_20 = lcpfn_model.predict_quantiles(x_train=x[:cutoff], y_train=y[:cutoff], x_test=x[cutoff:], qs=[0.05, 0.5, 0.95])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "5Jikycd-7CV_",
        "outputId": "43f47547-62a2-429e-9169-56cb1feea1ce"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Move x backward one unit\n",
        "for i in range(len(x_10)):\n",
        "  x_10[i] -= 1\n",
        "  x_20[i] -= 1\n",
        "\n",
        "\n",
        "# Plot target curves\n",
        "plt.plot(x_10, y_10, \"black\", label=\"Target for Cutoff 10\")\n",
        "plt.plot(x_20, y_20, \"grey\", label=\"Target for Cutoff 20\")\n",
        "\n",
        "# Plot extrapolations\n",
        "plt.plot(x_10[cutoff_10:], predictions_10[:, 1], \"blue\", label=\"Extrapolation for Cutoff 10\")\n",
        "plt.fill_between(x_10[cutoff_10:].flatten(), predictions_10[:, 0], predictions_10[:, 2], color=\"blue\", alpha=0.2, label=\"90% CI for Cutoff 10\")\n",
        "\n",
        "plt.plot(x_20[cutoff_20:], predictions_20[:, 1], \"green\", label=\"Extrapolation for Cutoff 20\")\n",
        "plt.fill_between(x_20[cutoff_20:].flatten(), predictions_20[:, 0], predictions_20[:, 2], color=\"green\", alpha=0.2, label=\"90% CI for Cutoff 20\")\n",
        "\n",
        "# Plot cutoff lines\n",
        "plt.axvline(x=cutoff_10, color='blue', linestyle='--', linewidth=0.5, label='Cutoff at 10')\n",
        "plt.axvline(x=cutoff_20, color='green', linestyle='--', linewidth=0.5, label='Cutoff at 20')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"Model Extrapolation with Different Cutoffs\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGTs0HtBjQyE"
      },
      "source": [
        "# Inference with MCMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "XCEK9mnHjQyE",
        "outputId": "e419c1c6-7994-4756-c2cd-85c39ab3c0df"
      },
      "outputs": [],
      "source": [
        "# MCMC code does not work with the same version of pytorch as the LC-PFN code\n",
        "\n",
        "%pip install torch --upgrade\n",
        "%pip install gpytorch\n",
        "%pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMY1hEY-jQyE"
      },
      "outputs": [],
      "source": [
        "from lcpfn.priors.fast_gp_mix import get_model\n",
        "\n",
        "\n",
        "def get_mcmc_model_variable_chains(x, y, hyperparameters, device, num_samples, warmup_steps, num_chains, obs=True):\n",
        "    from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
        "    import pyro\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    model, likelihood = get_model(x, y, hyperparameters, sample=False)\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    def pyro_model(x, y):\n",
        "        sampled_model = model.pyro_sample_from_prior()\n",
        "        output = sampled_model.likelihood(sampled_model(x))\n",
        "        if obs:\n",
        "            return pyro.sample(\"obs\", output, obs=y)\n",
        "\n",
        "    nuts_kernel = NUTS(pyro_model)\n",
        "    mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, num_chains=num_chains)#num_chains=1)\n",
        "    mcmc_run.run(x, y)\n",
        "    model.pyro_load_from_samples(mcmc_run.get_samples()) # pyro.infer wie noah?\n",
        "    model.eval()\n",
        "\n",
        "    return model, likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV8ryFE39hWU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# They tried\n",
        "# nsamples ∈ [100, 250, 500, 1000, 2000, 4000]\n",
        "# nwalkers ∈ [26, 50, 100]\n",
        "# burn-in ∈ [0, 50, 100, 500]\n",
        "# thin ∈ [1, 10, 100]\n",
        "\n",
        "hyperparameters = {'handmade': True} # Use the default handmade hyperparameters chosen by the authors\n",
        "device = 'cpu'\n",
        "num_samples = 100\n",
        "warmup_steps = 10\n",
        "num_chains = 100\n",
        "\n",
        "# For a cutoff of 10\n",
        "x = data_10['x']\n",
        "y = data_10['y']\n",
        "cutoff = data_10['cutoff']\n",
        "mcmc_model_10, likelihood_10 = get_mcmc_model_variable_chains(x[:cutoff].float(), y.flatten()[:cutoff].float(), hyperparameters, device, num_samples, warmup_steps, num_chains)\n",
        "with torch.no_grad():\n",
        "    predictions_10 = likelihood_10(mcmc_model_10(x[cutoff:].float()))\n",
        "    pred_mean_10 = predictions_10.mean.mean(0).squeeze()\n",
        "    pred_lower_10, pred_upper_10 = predictions_10.confidence_region()\n",
        "    pred_lower_10 = pred_lower_10.mean(0).squeeze()\n",
        "    pred_upper_10 = pred_upper_10.mean(0).squeeze()\n",
        "\n",
        "# For a cutoff of 20\n",
        "x = data_20['x']\n",
        "y = data_20['y']\n",
        "cutoff = data_20['cutoff']\n",
        "mcmc_model_20, likelihood_20 = get_mcmc_model_variable_chains(x[:cutoff].float(), y.flatten()[:cutoff].float(), hyperparameters, device, num_samples, warmup_steps, num_chains)\n",
        "with torch.no_grad():\n",
        "    predictions_20 = likelihood_20(mcmc_model_10(x[cutoff:].float()))\n",
        "    pred_mean_20 = predictions_20.mean.mean(0).squeeze()\n",
        "    pred_lower_20, pred_upper_20 = predictions_20.confidence_region()\n",
        "    pred_lower_20 = pred_upper_20.mean(0).squeeze()\n",
        "    pred_upper_20 = pred_upper_20.mean(0).squeeze()\n",
        "\n",
        "\n",
        "pred_mean_10, pred_mean_20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYStm3zpAP6N"
      },
      "outputs": [],
      "source": [
        "# Plotting the data and predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot predictions for cutoff = 10\n",
        "plt.plot(data_10['x'].flatten(), data_10['y'].flatten(), \"gray\", label=\"Data for Cutoff 10\")  # Actual data\n",
        "plt.plot(data_10['x'][data_10['cutoff']:].flatten(), pred_mean_10, \"blue\", label=\"Extrapolation for Cutoff 10\")\n",
        "plt.fill_between(data_10['x'][data_10['cutoff']:].flatten(), pred_lower_10, pred_upper_10, color=\"blue\", alpha=0.2, label=\"90% CI for Cutoff 10\")\n",
        "\n",
        "# Plot predictions for cutoff = 20\n",
        "plt.plot(data_20['x'].flatten(), data_20['y'].flatten(), \"lightgray\", label=\"Data for Cutoff 20\")  # Actual data\n",
        "plt.plot(data_20['x'][data_20['cutoff']:].flatten(), pred_mean_20, \"green\", label=\"Extrapolation for Cutoff 20\")\n",
        "plt.fill_between(data_20['x'][data_20['cutoff']:].flatten(), pred_lower_20, pred_upper_20, color=\"green\", alpha=0.2, label=\"90% CI for Cutoff 20\")\n",
        "\n",
        "# Plot cutoff lines\n",
        "plt.axvline(x=data_10['cutoff'], color='blue', linestyle='--', linewidth=0.5, label='Cutoff at 10')\n",
        "plt.axvline(x=data_20['cutoff'], color='green', linestyle='--', linewidth=0.5, label='Cutoff at 20')\n",
        "\n",
        "# Set plot limits, labels, title and legend\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"MCMC Model Extrapolation with Different Cutoffs\")\n",
        "plt.legend(loc=\"upper left\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
