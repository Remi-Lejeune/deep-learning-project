{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":31179,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":26153}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport sys\n\nsys.path.append(\"/kaggle/input/dl-project/pytorch/dl-datasets/1\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:37:52.889397Z","iopub.execute_input":"2024-04-14T19:37:52.890248Z","iopub.status.idle":"2024-04-14T19:37:52.914322Z","shell.execute_reply.started":"2024-04-14T19:37:52.890213Z","shell.execute_reply":"2024-04-14T19:37:52.913349Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"%cd -q ..","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:37:56.648600Z","iopub.execute_input":"2024-04-14T19:37:56.648975Z","iopub.status.idle":"2024-04-14T19:37:56.667985Z","shell.execute_reply.started":"2024-04-14T19:37:56.648945Z","shell.execute_reply":"2024-04-14T19:37:56.667128Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install torch==1.11.0","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:36:02.791495Z","iopub.execute_input":"2024-04-14T19:36:02.792248Z","iopub.status.idle":"2024-04-14T19:36:58.828879Z","shell.execute_reply.started":"2024-04-14T19:36:02.792210Z","shell.execute_reply":"2024-04-14T19:36:58.827607Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting torch==1.11.0\n  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.11.0) (4.9.0)\nDownloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.2.1 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\nstable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.11.0 which is incompatible.\ntorchdata 0.7.1 requires torch>=2, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-1.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import lcdb\nimport os\nimport json\nimport lcpfn \nimport torch as th\nfrom functools import partial\nimport numpy as np\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:37:59.691316Z","iopub.execute_input":"2024-04-14T19:37:59.692040Z","iopub.status.idle":"2024-04-14T19:38:01.352168Z","shell.execute_reply.started":"2024-04-14T19:37:59.692005Z","shell.execute_reply":"2024-04-14T19:38:01.351136Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip show torch","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:38:03.643062Z","iopub.execute_input":"2024-04-14T19:38:03.643621Z","iopub.status.idle":"2024-04-14T19:38:15.579602Z","shell.execute_reply.started":"2024-04-14T19:38:03.643587Z","shell.execute_reply":"2024-04-14T19:38:15.578391Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Name: torch\nVersion: 1.11.0\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: typing-extensions\nRequired-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision\n","output_type":"stream"}]},{"cell_type":"markdown","source":"DEFINE PATH","metadata":{}},{"cell_type":"code","source":"PATH = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:38:17.378052Z","iopub.execute_input":"2024-04-14T19:38:17.378404Z","iopub.status.idle":"2024-04-14T19:38:17.417050Z","shell.execute_reply.started":"2024-04-14T19:38:17.378379Z","shell.execute_reply":"2024-04-14T19:38:17.415869Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# path = \"C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q3\\\\Deep Learning\\\\deep-learning-project\\\\notebooks\\data.json\"\n\ndef readDatasetJson(path):\n    f = open(path)\n\n    dataset = json.load(f)\n    # print(len(dataset))\n    \n    x = []\n    y = []\n\n    for v in dataset.values():\n        x.append(v[0])\n        y.append(v[1])\n        \n    x_true = th.Tensor(x)\n    y_true = th.Tensor(y)\n    \n    return x_true, y_true\n\nimport os\ndef find_file(root_dir, target_filename):\n    for root, dirs, files in os.walk(root_dir):\n        if target_filename in files:\n            return os.path.join(root, target_filename)\n    \n    # If the loop completes without returning, the file was not found\n    return None\n\ndef find_data():\n    return find_file(os.getcwd(), 'data.json')\n\ndef get_data():\n    return readDatasetJson(find_data())\n\n# function producing batches for PFN training\ndef get_batch(\n    batch_size,\n    seq_len,\n    num_features,\n    device=\"cpu\",\n    noisy_target=True,\n    **_,\n):\n    assert num_features == 1\n\n    x_data, y_data = get_data()\n    \n    x_data = x_data[:batch_size, :]\n    y_data = y_data[:batch_size, :]\n\n    y_data_noisy = y_data.clone()\n\n    x_data = x_data.view((num_features, batch_size, seq_len)).transpose(2, 0).to(device)\n    y_data = y_data.transpose(1, 0).to(device)\n    y_data_noisy = y_data.clone()\n\n    return x_data, y_data, y_data_noisy","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:38:18.918286Z","iopub.execute_input":"2024-04-14T19:38:18.918659Z","iopub.status.idle":"2024-04-14T19:38:18.958643Z","shell.execute_reply.started":"2024-04-14T19:38:18.918629Z","shell.execute_reply":"2024-04-14T19:38:18.957642Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=256,\n                         nlayers=12,\n                         lr=0.001,\n                         batch_size=1651,\n                         epochs=15)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_1651.pth\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:33:39.675082Z","iopub.execute_input":"2024-04-14T19:33:39.676372Z","iopub.status.idle":"2024-04-14T19:34:51.757400Z","shell.execute_reply.started":"2024-04-14T19:33:39.676326Z","shell.execute_reply":"2024-04-14T19:34:51.756004Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Using cpu:0 device\ninit dist\nNot using distributed\nDataLoader.__dict__ {'num_steps': 100, 'get_batch_kwargs': {'batch_size': 1651, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x79bfcd993520>, 'seq_len_maximum': 26, 'device': 'cpu:0', 'num_features': 1, 'hyperparameters': {}}, 'num_features': 1}\nStyle definition: None\nUsing a Transformer with 6.46 M parameters\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n","output_type":"stream"}]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=256,\n                         nlayers=12,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=15)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_256_12.pth\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:38:23.353045Z","iopub.execute_input":"2024-04-14T19:38:23.353799Z","iopub.status.idle":"2024-04-14T19:47:14.859303Z","shell.execute_reply.started":"2024-04-14T19:38:23.353764Z","shell.execute_reply":"2024-04-14T19:47:14.858255Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Using cuda:0 device\ninit dist\nNot using distributed\nDataLoader.__dict__ {'num_steps': 100, 'get_batch_kwargs': {'batch_size': 1000, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x7fc93ebf2d40>, 'seq_len_maximum': 26, 'device': 'cuda:0', 'num_features': 1, 'hyperparameters': {}}, 'num_features': 1}\nStyle definition: None\nUsing a Transformer with 6.46 M parameters\n-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 35.12s | mean loss  0.70 | pos losses   nan, 0.70, 0.70, 0.70, 0.70, 0.70, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.71, lr 0.0 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   2 | time: 35.15s | mean loss  0.05 | pos losses   nan, 0.15, 0.02, 0.01, 0.03, 0.20, 0.04, 0.01, 0.01, 0.01, 0.01, 0.04, 0.03, 0.02, 0.02,  nan, 0.06, 0.02, 0.01, 0.01, 0.08, 0.01, 0.04, 0.01, 0.21, 0.01, lr 0.0003333333333333333 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   3 | time: 35.22s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,  nan, 0.01, 0.01, 0.01, 0.01, 0.01,  nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.01, 0.01, 0.01, 0.01, 0.01, lr 0.0006666666666666666 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   4 | time: 35.25s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, lr 0.001 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   5 | time: 35.28s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,  nan, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.01, lr 0.0009829629131445341 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   6 | time: 35.18s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00,  nan, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0009330127018922195 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   7 | time: 35.20s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0008535533905932737 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   8 | time: 35.32s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.00075 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   9 | time: 35.24s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0006294095225512603 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  10 | time: 35.29s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0005 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  11 | time: 35.34s | mean loss  0.00 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0003705904774487396 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  12 | time: 35.26s | mean loss  0.01 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.0002500000000000001 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  13 | time: 35.30s | mean loss  0.00 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 0.00014644660940672628 data time  0.17 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  14 | time: 35.17s | mean loss  0.00 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00, 0.00, 0.00, 0.00,  nan, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 6.698729810778065e-05 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch  15 | time: 35.26s | mean loss  0.00 | pos losses   nan, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,  nan, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, lr 1.70370868554659e-05 data time  0.08 step time  0.26 forward time  0.01\n-----------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=256,\n                         nlayers=10,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=5)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_256_12.pth\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:49:53.135793Z","iopub.execute_input":"2024-04-14T19:49:53.136610Z","iopub.status.idle":"2024-04-14T19:52:27.902092Z","shell.execute_reply.started":"2024-04-14T19:49:53.136580Z","shell.execute_reply":"2024-04-14T19:52:27.901073Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Using cuda:0 device\ninit dist\nNot using distributed\nDataLoader.__dict__ {'num_steps': 100, 'get_batch_kwargs': {'batch_size': 1000, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x7fc93ebf31c0>, 'seq_len_maximum': 26, 'device': 'cuda:0', 'num_features': 1, 'hyperparameters': {}}, 'num_features': 1}\nStyle definition: None\nUsing a Transformer with 5.40 M parameters\n-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 30.94s | mean loss  1.26 | pos losses   nan, 1.26, 1.26, 1.26, 1.27, 1.27, 1.27, 1.27, 1.27, 1.27, 1.27, 1.27, 1.27,  nan, 1.27, 1.26, 1.26, 1.26, 1.26, 1.26, 1.26, 1.26, 1.26, 1.26, 1.27, 1.27, lr 0.0 data time  0.08 step time  0.22 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   2 | time: 30.97s | mean loss  0.08 | pos losses   nan, 0.10, 0.05, 0.05, 0.09, 0.05, 0.06, 0.09, 0.30, 0.04, 0.04, 0.04, 0.04, 0.04, 0.05, 0.12, 0.04, 0.04, 0.20, 0.06, 0.04, 0.14, 0.06, 0.04, 0.04, 0.04, lr 0.001 data time  0.08 step time  0.22 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   3 | time: 30.88s | mean loss  0.04 | pos losses   nan, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,  nan, 0.04, 0.04, 0.04, 0.04, lr 0.0008535533905932737 data time  0.19 step time  0.22 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   4 | time: 30.76s | mean loss  0.04 | pos losses   nan, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, lr 0.0005 data time  0.08 step time  0.22 forward time  0.01\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| end of epoch   5 | time: 30.98s | mean loss  0.04 | pos losses   nan, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, lr 0.00014644660940672628 data time  0.08 step time  0.22 forward time  0.01\n-----------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=256,\n                         nlayers=18,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=5)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_256_8.pth\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=128,\n                         nlayers=12,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=5)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_128_12.pth\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=128,\n                         nlayers=10,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=5)\n\nth.save(result[2].state_dict(), PATH + \"\\\\model_128_10.pth\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n                         seq_len=26,\n                         emsize=128,\n                         nlayers=8,\n                         lr=0.001,\n                         batch_size=1000,\n                         epochs=5)\n\nth.save(result[2].state_dict(), os.path.join(PATH, \"model_128_8.pth\"))","metadata":{},"execution_count":null,"outputs":[]}]}