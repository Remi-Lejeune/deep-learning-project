{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e8cf01df-787c-49ef-83f2-e08bce88506f",
      "metadata": {
        "id": "e8cf01df-787c-49ef-83f2-e08bce88506f",
        "outputId": "2d3dfd25-f45d-4b76-cac4-a4371b64a2fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b wreckin https://github.com/Remi-Lejeune/deep-learning-project/"
      ],
      "metadata": {
        "id": "TzpB0fQ-AHsS",
        "outputId": "8632867d-907c-4f50-bc25-e815a6c69df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TzpB0fQ-AHsS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-project'...\n",
            "remote: Enumerating objects: 626, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-learning-project/"
      ],
      "metadata": {
        "id": "HluknzcEASBq",
        "outputId": "f8ca45b1-a3cf-4054-cc5d-5aa57d3cc382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HluknzcEASBq",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install python 3.9\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "#3.9.16"
      ],
      "metadata": {
        "id": "Hrakw1LSAWBP",
        "outputId": "71a675ef-9c4e-40e4-f1ab-ca934ed5d1db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Hrakw1LSAWBP",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [1 InRelease 9,826 B/110 k\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [1 InRelease 25.8 kB/110 k\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [1 InRelease 59.1 kB/110 k\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Waiting for headers] [Wai\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Waiting for headers] [3 I\r                                                                               \r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Waiting for headers]\r                                                                          \rHit:4 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\r                                                                          \r0% [Waiting for headers]\r                        \rGet:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "\r0% [Waiting for headers] [5 InRelease 18.1 kB/18.1 kB 100%]\r                                                           \r0% [Waiting for headers]\r                        \rHit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers]\r                        \rHit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [808 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Hit:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n",
            "Fetched 11.6 MB in 2s (6,879 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib mailcap mime-support\n",
            "  python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib mailcap mime-support python3.9\n",
            "  python3.9-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 5,275 kB of archives.\n",
            "After this operation, 19.4 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-minimal amd64 3.9.19-1+jammy1 [835 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-minimal amd64 3.9.19-1+jammy1 [2,073 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-stdlib amd64 3.9.19-1+jammy1 [1,842 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9 amd64 3.9.19-1+jammy1 [497 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Fetched 5,275 kB in 0s (15.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.9-stdlib_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../5-python3.9_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.19-1+jammy1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-minimal (3.9.19-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9 (3.9.19-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "update-alternatives: error: alternative path /usr/bin/python3.8 doesn't exist\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.9.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bootstrap.pypa.io/get-pip.py"
      ],
      "metadata": {
        "id": "_avwq5BeAYZb",
        "outputId": "c9c5d3d3-a944-4894-cbee-4276afaba7f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_avwq5BeAYZb",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-14 19:07:20--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2635835 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "\rget-pip.py            0%[                    ]       0  --.-KB/s               \rget-pip.py          100%[===================>]   2.51M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 19:07:20 (103 MB/s) - ‘get-pip.py’ saved [2635835/2635835]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.9-distutils"
      ],
      "metadata": {
        "id": "ZqYTHLObAdAJ",
        "outputId": "7fc96d6b-44ec-4225-aa6f-42629de28f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZqYTHLObAdAJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.9-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.9-distutils python3.9-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,234 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.19-1+jammy1 [127 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.19-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 0s (1,832 kB/s)\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "(Reading database ... 122417 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.9-lib2to3_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../python3.9-distutils_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.19-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 get-pip.py"
      ],
      "metadata": {
        "id": "Z5MZDZEKAgSW",
        "outputId": "b0d5b1e7-3867-4d20-89fd-978fcdf5ba93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z5MZDZEKAgSW",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.0 setuptools-69.5.1 wheel-0.43.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove jupyter from this in colab\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8pxJ8UhIAlPy",
        "outputId": "72472184-408a-4f8e-9aee-b4eb9a04063a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8pxJ8UhIAlPy",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.66.2)\n",
            "Requirement already satisfied: func-timeout in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (4.3.5)\n",
            "Requirement already satisfied: lcdb in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (0.1.0)\n",
            "Requirement already satisfied: openml in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.14.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.11.0->-r requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 6)) (6.4.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from openml->-r requirements.txt (line 11)) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.9/dist-packages (from openml->-r requirements.txt (line 11)) (0.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from openml->-r requirements.txt (line 11)) (2.31.0)\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.9/dist-packages (from openml->-r requirements.txt (line 11)) (7.2.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (from openml->-r requirements.txt (line 11)) (15.0.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 6)) (3.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from minio->openml->-r requirements.txt (line 11)) (2024.2.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from minio->openml->-r requirements.txt (line 11)) (2.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from minio->openml->-r requirements.txt (line 11)) (23.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.9/dist-packages (from minio->openml->-r requirements.txt (line 11)) (3.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->openml->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->openml->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->minio->openml->-r requirements.txt (line 11)) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml->-r requirements.txt (line 11)) (2.22)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a3c2921e-45c2-4080-8c90-089daeeceba0",
      "metadata": {
        "id": "a3c2921e-45c2-4080-8c90-089daeeceba0"
      },
      "outputs": [],
      "source": [
        "import lcdb\n",
        "import json\n",
        "import lcpfn\n",
        "import torch as th\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d3535d",
      "metadata": {
        "id": "66d3535d"
      },
      "source": [
        "DEFINE PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "61fe4013",
      "metadata": {
        "id": "61fe4013",
        "outputId": "c1550fbb-b2ac-47ed-9535-e2f34843a6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/deep-learning-project/notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import os\n",
        "PATH = os.path.join(os.getcwd(), 'notebooks')\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "eac6fdb7",
      "metadata": {
        "id": "eac6fdb7"
      },
      "outputs": [],
      "source": [
        "# path = \"C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q3\\\\Deep Learning\\\\deep-learning-project\\\\notebooks\\data.json\"\n",
        "\n",
        "def readDatasetJson(path):\n",
        "    f = open(path)\n",
        "\n",
        "    dataset = json.load(f)\n",
        "    # print(len(dataset))\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for v in dataset.values():\n",
        "        x.append(v[0])\n",
        "        y.append(v[1])\n",
        "\n",
        "    x_true = th.Tensor(x)\n",
        "    y_true = th.Tensor(y)\n",
        "\n",
        "    return x_true, y_true\n",
        "\n",
        "import os\n",
        "def find_file(root_dir, target_filename):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        if target_filename in files:\n",
        "            return os.path.join(root, target_filename)\n",
        "\n",
        "    # If the loop completes without returning, the file was not found\n",
        "    return None\n",
        "\n",
        "def find_data():\n",
        "    return find_file(os.getcwd(), 'data.json')\n",
        "\n",
        "def get_data():\n",
        "    return readDatasetJson(find_data())\n",
        "\n",
        "# function producing batches for PFN training\n",
        "def get_batch(\n",
        "    batch_size,\n",
        "    seq_len,\n",
        "    num_features,\n",
        "    device=\"cpu\",\n",
        "    noisy_target=True,\n",
        "    **_,\n",
        "):\n",
        "    assert num_features == 1\n",
        "\n",
        "    x_data, y_data = get_data()\n",
        "    print(x_data.shape)\n",
        "    x_data = x_data[:batch_size, :]\n",
        "    y_data = y_data[:batch_size, :]\n",
        "\n",
        "    y_data_noisy = y_data.clone()\n",
        "\n",
        "    x_data = x_data.view((num_features, batch_size, seq_len)).transpose(2, 0).to(device)\n",
        "    y_data = y_data.transpose(1, 0).to(device)\n",
        "    y_data_noisy = y_data.clone()\n",
        "\n",
        "    return x_data, y_data, y_data_noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "aa7ce7fb-9c9f-4858-ab2e-b86bd48d15c9",
      "metadata": {
        "id": "aa7ce7fb-9c9f-4858-ab2e-b86bd48d15c9",
        "outputId": "4f4b88a8-ff73-431d-96e9-60e630abe777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3302, 26])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[1, 10000, 26]' is invalid for input of size 85852",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-797229afa14c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0memsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-project/lcpfn/train_lcpfn.py\u001b[0m in \u001b[0;36mtrain_lcpfn\u001b[0;34m(get_batch_func, seq_len, emsize, nlayers, num_borders, lr, batch_size, epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#LALA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     ys = get_batch_func(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;36m10_000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#HELLA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-e8d8f17cfb86>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size, seq_len, num_features, device, noisy_target, **_)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0my_data_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0my_data_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 10000, 26]' is invalid for input of size 85852"
          ]
        }
      ],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=256,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1651,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_1651.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741f18b3",
      "metadata": {
        "id": "741f18b3"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=256,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_256_12.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2d15c7",
      "metadata": {
        "id": "9d2d15c7"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=256,\n",
        "                         nlayers=10,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_256_10.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d804122",
      "metadata": {
        "id": "6d804122"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=256,\n",
        "                         nlayers=18,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_256_8.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a19db7",
      "metadata": {
        "id": "e0a19db7"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=128,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_128_12.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e07a5f",
      "metadata": {
        "id": "14e07a5f"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=128,\n",
        "                         nlayers=10,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_128_10.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8152d42f",
      "metadata": {
        "id": "8152d42f"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=128,\n",
        "                         nlayers=8,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1000,\n",
        "                         epochs=15)\n",
        "\n",
        "th.save(result[2].state_dict(), os.path.join(PATH, 'model_128_8.txt'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
