{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lcdb\n",
    "import json\n",
    "import lcpfn \n",
    "import torch as th\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q3\\\\Deep Learning\\\\deep-learning-project\\\\notebooks\\data.json\"\n",
    "\n",
    "def readDatasetJson(path):\n",
    "    f = open(path)\n",
    "\n",
    "    dataset = json.load(f)\n",
    "    # print(len(dataset))\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for v in dataset.values():\n",
    "        x.append(v[0])\n",
    "        y.append(v[1])\n",
    "        \n",
    "    x_true = th.Tensor(x)\n",
    "    y_true = th.Tensor(y)\n",
    "    \n",
    "    return x_true, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def find_file(root_dir, target_filename):\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        if target_filename in files:\n",
    "            return os.path.join(root, target_filename)\n",
    "    \n",
    "    # If the loop completes without returning, the file was not found\n",
    "    return None\n",
    "\n",
    "def find_data():\n",
    "    return find_file(os.getcwd(), 'data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return readDatasetJson(find_data())\n",
    "\n",
    "x, y = readDatasetJson(find_data())\n",
    "perm = th.randperm(x.size(0))\n",
    "x = x[perm]\n",
    "y = y[perm]\n",
    "\n",
    "x_train = x[:x.shape[0]//2] \n",
    "x_test = x[x.shape[0]//2:]\n",
    "\n",
    "y_train = y[:y.shape[0]//2] \n",
    "y_test = y[y.shape[0]//2:]\n",
    "\n",
    "batch_size = x_train.shape[0]\n",
    "\n",
    "def getBatch(training_set_x, training_set_y):\n",
    "    return training_set_x, training_set_y\n",
    "\n",
    "def getTrainBatchFunc():\n",
    "    return partial(getBatch, x_train, y_train)\n",
    "\n",
    "def getTestBatchFunc():\n",
    "    return partial(getBatch, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function producing batches for PFN training\n",
    "def get_batch(\n",
    "    batch_size,\n",
    "    seq_len,\n",
    "    num_features,\n",
    "    device=\"cpu\",\n",
    "    noisy_target=True,\n",
    "    **_,\n",
    "):\n",
    "    assert num_features == 1\n",
    "\n",
    "    #x_data, y_data = get_data()\n",
    "    func = getTrainBatchFunc()\n",
    "    x_data, y_data = func()\n",
    "    \n",
    "    x_data = x_data[:batch_size, :]\n",
    "    y_data = y_data[:batch_size, :]\n",
    "\n",
    "    y_data_noisy = y_data.clone()\n",
    "\n",
    "    # print(x_data.shape)\n",
    "    # print(y_data.shape)\n",
    "\n",
    "    x_data = x_data.view((num_features, batch_size, seq_len)).transpose(2, 0).to(device)\n",
    "    y_data = y_data.transpose(1, 0).to(device)\n",
    "    y_data_noisy = y_data.clone()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # x = np.arange(1, seq_len + 1)\n",
    "    # y_target = np.empty((batch_size, seq_len), dtype=float)\n",
    "    # y_noisy = np.empty((batch_size, seq_len), dtype=float)\n",
    "    # x_data, y_data = get_data() # uses numpy rng\n",
    "    \n",
    "    # for i in range(batch_size):    \n",
    "    #     if noisy_target:\n",
    "    #         y_noisy[i] = y_data[i]\n",
    "    #         y_target[i] = y_data[i]\n",
    "    #     else:\n",
    "    #         y_target[i], y_noisy[i] = y_data[i]\n",
    "    # # turn numpy arrays into correctly shaped torch tensors & move them to device\n",
    "    # x = (\n",
    "    #     th.Tensor(x_data[0])\n",
    "    #     .repeat((num_features, batch_size, 1))\n",
    "    #     .transpose(2, 0)\n",
    "    #     .to(device)\n",
    "    # )\n",
    "    # y_target = th.from_numpy(y_target).transpose(1, 0).to(device)\n",
    "    # y_noisy = th.from_numpy(y_noisy).transpose(1, 0).to(device)\n",
    "\n",
    "    # # changes\n",
    "    # x = x.float()\n",
    "    # y_target = y_target.float()\n",
    "    # y_noisy = y_noisy.float()\n",
    "    \n",
    "    # return x, y_noisy, y_target\n",
    "\n",
    "    return x_data, y_data, y_data_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n",
    "                         seq_len=26,\n",
    "                         emsize=256,\n",
    "                         nlayers=12,\n",
    "                         lr=0.001,\n",
    "                         batch_size=1651,\n",
    "                         epochs=20)\n",
    "th.save(result[2].state_dict(), 'model_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n",
    "                         seq_len=26,\n",
    "                         emsize=128,\n",
    "                         nlayers=12,\n",
    "                         lr=0.001,\n",
    "                         batch_size=1651,\n",
    "                         epochs=20)\n",
    "th.save(result[2].state_dict(), 'model_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n",
    "                         seq_len=26,\n",
    "                         emsize=64,\n",
    "                         nlayers=12,\n",
    "                         lr=0.001,\n",
    "                         batch_size=1651,\n",
    "                         epochs=20)\n",
    "th.save(result[2].state_dict(), 'model_3.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
