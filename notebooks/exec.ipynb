{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EraJb5GNPgbR",
        "outputId": "65250b6f-9a29-4eca-9656-e79cba0f704e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fwUZEBswPgbS",
        "outputId": "e6cf675b-8c2f-43da-a482-2947d2d943da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-project'...\n",
            "remote: Enumerating objects: 562, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 562 (delta 50), reused 24 (delta 20), pack-reused 495\u001b[K\n",
            "Receiving objects: 100% (562/562), 248.19 MiB | 22.53 MiB/s, done.\n",
            "Resolving deltas: 100% (258/258), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Remi-Lejeune/deep-learning-project/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-learning-project/"
      ],
      "metadata": {
        "id": "jR16TFQZPwI4",
        "outputId": "6591cb03-cd11-4da1-9ff5-5fa13ae39e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install python 3.9\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "#3.9.16"
      ],
      "metadata": {
        "id": "jcU81qoFP_7Y",
        "outputId": "46e3fbe1-6294-409e-86f0-024f495b151c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [808 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Fetched 11.6 MB in 3s (3,663 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib mailcap mime-support\n",
            "  python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib mailcap mime-support python3.9\n",
            "  python3.9-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 5,275 kB of archives.\n",
            "After this operation, 19.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-minimal amd64 3.9.19-1+jammy1 [835 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-minimal amd64 3.9.19-1+jammy1 [2,073 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-stdlib amd64 3.9.19-1+jammy1 [1,842 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9 amd64 3.9.19-1+jammy1 [497 kB]\n",
            "Fetched 5,275 kB in 3s (2,059 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.9-stdlib_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../5-python3.9_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.19-1+jammy1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-minimal (3.9.19-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9 (3.9.19-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "update-alternatives: error: alternative path /usr/bin/python3.8 doesn't exist\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.9.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bootstrap.pypa.io/get-pip.py"
      ],
      "metadata": {
        "id": "kKKY7NvjQCZs",
        "outputId": "0d1a934a-8141-4756-ec37-e53406f9616c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-14 15:36:51--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2635835 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "\rget-pip.py            0%[                    ]       0  --.-KB/s               \rget-pip.py          100%[===================>]   2.51M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-04-14 15:36:51 (32.7 MB/s) - ‘get-pip.py’ saved [2635835/2635835]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.9-distutils"
      ],
      "metadata": {
        "id": "F34HbEHEQdN0",
        "outputId": "d66dadbf-01d4-4d64-bac3-7e276265fa44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.9-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.9-distutils python3.9-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,234 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.19-1+jammy1 [127 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.19-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 2s (151 kB/s)\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "(Reading database ... 122417 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.9-lib2to3_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../python3.9-distutils_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.19-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 get-pip.py"
      ],
      "metadata": {
        "id": "BBOoo668QVar",
        "outputId": "86fe5807-32e9-44ef-add3-d72876ca35ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.0 setuptools-69.5.1 wheel-0.43.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "7gfIRnT7Qmg1",
        "outputId": "c1faef82-0d66-4f85-915a-747199fffe0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11.0 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting numpy>=1.21.2 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter (from -r requirements.txt (line 3))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting pandas (from -r requirements.txt (line 5))\n",
            "  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scikit-learn (from -r requirements.txt (line 6))\n",
            "  Downloading scikit_learn-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting matplotlib (from -r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting scipy (from -r requirements.txt (line 8))\n",
            "  Downloading scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 9))\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting func-timeout (from -r requirements.txt (line 10))\n",
            "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lcdb (from -r requirements.txt (line 11))\n",
            "  Downloading lcdb-0.1.0.tar.gz (68.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openml (from -r requirements.txt (line 12))\n",
            "  Downloading openml-0.14.2.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions (from torch==1.11.0->-r requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting notebook (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading notebook-7.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting qtconsole (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jupyter-console (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nbconvert (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading nbconvert-7.16.3-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ipykernel (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipywidgets (from jupyter->-r requirements.txt (line 3))\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->-r requirements.txt (line 5))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 5))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 5))\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 6))\n",
            "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 6))\n",
            "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading fonttools-4.51.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting importlib-resources>=3.2.0 (from matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting liac-arff>=2.4.0 (from openml->-r requirements.txt (line 12))\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict (from openml->-r requirements.txt (line 12))\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting requests (from openml->-r requirements.txt (line 12))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting minio (from openml->-r requirements.txt (line 12))\n",
            "  Downloading minio-7.2.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pyarrow (from openml->-r requirements.txt (line 12))\n",
            "  Downloading pyarrow-15.0.2-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 7))\n",
            "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading debugpy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting nest-asyncio (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting psutil (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting pyzmq>=24 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading pyzmq-25.1.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading traitlets-5.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting widgetsnbextension~=4.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting prompt-toolkit>=3.0.30 (from jupyter-console->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pygments (from jupyter-console->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting certifi (from minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting urllib3 (from minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting argon2-cffi (from minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pycryptodome (from minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting beautifulsoup4 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bleach!=5.0.0 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting defusedxml (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting importlib-metadata>=3.6 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting jinja2>=3.0 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting jupyterlab-pygments (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting markupsafe>=2.0 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting nbclient>=0.5.0 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting nbformat>=5.7 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting tinycss2 (from nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_server-2.14.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.22.1 (from notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyterlab_server-2.26.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyterlab<4.2,>=4.1.1 (from notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyterlab-4.1.6-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->openml->-r requirements.txt (line 12))\n",
            "  Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->openml->-r requirements.txt (line 12))\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting argon2-cffi-bindings (from argon2-cffi->minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting httpx>=0.25.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tomli>=1.2.2 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting wcwidth (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading rpds_py-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyyaml>=5.3 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi->minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml->-r requirements.txt (line 12))\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 3))\n",
            "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/750.6 MB\u001b[0m \u001b[31m613.3 kB/s\u001b[0m eta \u001b[36m0:18:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3glHguJPgbS"
      },
      "outputs": [],
      "source": [
        "import lcdb\n",
        "import json\n",
        "import lcpfn\n",
        "import torch as th\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7ssou4_PgbS"
      },
      "outputs": [],
      "source": [
        "# path = \"C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q3\\\\Deep Learning\\\\deep-learning-project\\\\notebooks\\data.json\"\n",
        "\n",
        "def readDatasetJson(path):\n",
        "    f = open(path)\n",
        "\n",
        "    dataset = json.load(f)\n",
        "    # print(len(dataset))\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for v in dataset.values():\n",
        "        x.append(v[0])\n",
        "        y.append(v[1])\n",
        "\n",
        "    x_true = th.Tensor(x)\n",
        "    y_true = th.Tensor(y)\n",
        "\n",
        "    return x_true, y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnlOq-MXPgbT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def find_file(root_dir, target_filename):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        if target_filename in files:\n",
        "            return os.path.join(root, target_filename)\n",
        "\n",
        "    # If the loop completes without returning, the file was not found\n",
        "    return None\n",
        "\n",
        "def find_data():\n",
        "    return find_file(os.getcwd(), 'data.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7qQfyf4PgbT"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    return readDatasetJson(find_data())\n",
        "\n",
        "x, y = readDatasetJson(find_data())\n",
        "perm = th.randperm(x.size(0))\n",
        "x = x[perm]\n",
        "y = y[perm]\n",
        "\n",
        "x_train = x[:x.shape[0]//2]\n",
        "x_test = x[x.shape[0]//2:]\n",
        "\n",
        "y_train = y[:y.shape[0]//2]\n",
        "y_test = y[y.shape[0]//2:]\n",
        "\n",
        "batch_size = x_train.shape[0]\n",
        "\n",
        "def getBatch(training_set_x, training_set_y):\n",
        "    return training_set_x, training_set_y\n",
        "\n",
        "def getTrainBatchFunc():\n",
        "    return partial(getBatch, x_train, y_train)\n",
        "\n",
        "def getTestBatchFunc():\n",
        "    return partial(getBatch, x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAai_-H9PgbT"
      },
      "outputs": [],
      "source": [
        "# function producing batches for PFN training\n",
        "def get_batch(\n",
        "    batch_size,\n",
        "    seq_len,\n",
        "    num_features,\n",
        "    device=\"cpu\",\n",
        "    noisy_target=True,\n",
        "    **_,\n",
        "):\n",
        "    assert num_features == 1\n",
        "\n",
        "    #x_data, y_data = get_data()\n",
        "    func = getTrainBatchFunc()\n",
        "    x_data, y_data = func()\n",
        "\n",
        "    x_data = x_data[:batch_size, :]\n",
        "    y_data = y_data[:batch_size, :]\n",
        "\n",
        "    y_data_noisy = y_data.clone()\n",
        "\n",
        "    # print(x_data.shape)\n",
        "    # print(y_data.shape)\n",
        "\n",
        "    x_data = x_data.view((num_features, batch_size, seq_len)).transpose(2, 0).to(device)\n",
        "    y_data = y_data.transpose(1, 0).to(device)\n",
        "    y_data_noisy = y_data.clone()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # x = np.arange(1, seq_len + 1)\n",
        "    # y_target = np.empty((batch_size, seq_len), dtype=float)\n",
        "    # y_noisy = np.empty((batch_size, seq_len), dtype=float)\n",
        "    # x_data, y_data = get_data() # uses numpy rng\n",
        "\n",
        "    # for i in range(batch_size):\n",
        "    #     if noisy_target:\n",
        "    #         y_noisy[i] = y_data[i]\n",
        "    #         y_target[i] = y_data[i]\n",
        "    #     else:\n",
        "    #         y_target[i], y_noisy[i] = y_data[i]\n",
        "    # # turn numpy arrays into correctly shaped torch tensors & move them to device\n",
        "    # x = (\n",
        "    #     th.Tensor(x_data[0])\n",
        "    #     .repeat((num_features, batch_size, 1))\n",
        "    #     .transpose(2, 0)\n",
        "    #     .to(device)\n",
        "    # )\n",
        "    # y_target = th.from_numpy(y_target).transpose(1, 0).to(device)\n",
        "    # y_noisy = th.from_numpy(y_noisy).transpose(1, 0).to(device)\n",
        "\n",
        "    # # changes\n",
        "    # x = x.float()\n",
        "    # y_target = y_target.float()\n",
        "    # y_noisy = y_noisy.float()\n",
        "\n",
        "    # return x, y_noisy, y_target\n",
        "\n",
        "    return x_data, y_data, y_data_noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVcrn6sRPgbT"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=256,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1651,\n",
        "                         epochs=20)\n",
        "th.save(result[2].state_dict(), 'model_1.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPPETeNPPgbT"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=128,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1651,\n",
        "                         epochs=20)\n",
        "th.save(result[2].state_dict(), 'model_2.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKbEcfJEPgbU"
      },
      "outputs": [],
      "source": [
        "result = lcpfn.train_lcpfn(get_batch_func=get_batch,\n",
        "                         seq_len=26,\n",
        "                         emsize=64,\n",
        "                         nlayers=12,\n",
        "                         lr=0.001,\n",
        "                         batch_size=1651,\n",
        "                         epochs=20)\n",
        "th.save(result[2].state_dict(), 'model_3.txt')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}