{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remil\\.conda\\envs\\lcpfn\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd -q ..\n",
    "\n",
    "\n",
    "import lcpfn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layers, num_layers=num_layers\n",
    "        )\n",
    "        self.encoder = nn.Linear(input_dim, model_dim)\n",
    "        self.decoder = nn.Linear(model_dim, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    # forwards pass\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.model_dim)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        src = self.dropout(src)\n",
    "\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        # Use the representation of the last position\n",
    "        output = self.decoder(output)\n",
    "        output = output[:, -1, :]\n",
    "        return output.squeeze(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Used to test our models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def test(model):\n",
    "\n",
    "    get_batch_func = lcpfn.create_get_batch_func(prior=lcpfn.sample_from_prior)\n",
    "    X, Y, Y_noisy = get_batch_func(batch_size=100, seq_len=100, num_features=1)\n",
    "    Y = Y.permute(1, 0)\n",
    "\n",
    "    dataset = TensorDataset(Y, Y)\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=5, shuffle=False\n",
    "    )\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "\n",
    "    for input_sequence, target_sequence in data_loader:\n",
    "        model.eval()\n",
    "\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "\n",
    "        input_sequence = input_sequence.unsqueeze(-1)  # [batch_size, input_length, features]\n",
    "\n",
    "        step_loss = 0\n",
    "\n",
    "        current_input = input_sequence[:,:15]\n",
    "\n",
    "\n",
    "        for i in range(15, 99):\n",
    "\n",
    "            prediction = model(current_input)\n",
    "\n",
    "            loss = criterion(prediction, target_sequence[:, i + 1])\n",
    "            step_loss += loss\n",
    "\n",
    "            current_input =  torch.cat((current_input, prediction.unsqueeze(-1).unsqueeze(-1)), dim=1)\n",
    "\n",
    "        total_loss += step_loss\n",
    "\n",
    "    print(f\"Loss: {total_loss / len(data_loader)}\")\n",
    "    return total_loss / len(data_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "model = torch.load('small_model_no_teaching_euclidean.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loss: 4.238088130950928\n",
      "Loss: 4.261197090148926\n",
      "Loss: 3.578749179840088\n",
      "Loss: 3.11883282661438\n",
      "Loss: 4.031520366668701\n",
      "Loss: 2.3648316860198975\n",
      "Loss: 4.415432929992676\n",
      "Loss: 7.342675685882568\n",
      "Loss: 5.032954692840576\n",
      "Loss: 3.9560811519622803\n",
      "mean: tensor(4.2340)\n",
      "std: tensor(1.3174)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        results.append(test(model))\n",
    "\n",
    "results = torch.tensor(results)\n",
    "print(\"mean:\", torch.mean(results))\n",
    "print(\"std:\", torch.std(results))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Used to test their models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def test_LCPFN():\n",
    "\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    for i in range(100):\n",
    "        model = lcpfn.LCPFN()\n",
    "\n",
    "        prior = lcpfn.sample_from_prior(np.random)\n",
    "        curve, _ = prior()\n",
    "\n",
    "\n",
    "        x = torch.arange(1, 101).unsqueeze(1)\n",
    "        y = torch.from_numpy(curve).float().unsqueeze(1)\n",
    "\n",
    "        cutoff = 15\n",
    "\n",
    "        pred = model.predict_mean(x_train=x[:cutoff], y_train=y[:cutoff], x_test=x[cutoff:])\n",
    "        loss = criterion(y[cutoff:], pred)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Loss: {total_loss / 100}\")\n",
    "\n",
    "    return total_loss/100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loss: 0.0002437597459966234\n",
      "Loss: 0.0001133347373431448\n",
      "Loss: 0.00019366741526180675\n",
      "Loss: 0.0003397745910585215\n",
      "Loss: 0.00019523907275143415\n",
      "Loss: 0.00023576721137182232\n",
      "Loss: 0.00024106429422417362\n",
      "Loss: 0.00025883323125299286\n",
      "Loss: 0.0002560805691150847\n",
      "Loss: 0.0002724775551940439\n",
      "mean: tensor(0.0002)\n",
      "std: tensor(5.9255e-05)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        results.append(test_LCPFN())\n",
    "\n",
    "results = torch.tensor(results)\n",
    "print(\"mean:\", torch.mean(results))\n",
    "print(\"std:\", torch.std(results))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code to make the graphs (saved in graphs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "def get_results(cutoff, y, model):\n",
    "\n",
    "    def predict_single_sequence(input_sequence):\n",
    "        model.eval()  # Ensure the model is in eval mode\n",
    "        with torch.no_grad():  # No gradients needed\n",
    "            # Assuming input_sequence is already a PyTorch tensor with the right shape and dtype\n",
    "            prediction = model(input_sequence).to(device)\n",
    "            # Convert the prediction back to a Python number for easy interpretation\n",
    "            predicted_value = prediction.item()\n",
    "        return predicted_value\n",
    "\n",
    "    # Example usage\n",
    "    input_data = y[:cutoff].unsqueeze(0).to(device)  # Example input sequence\n",
    "\n",
    "    result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
    "\n",
    "    for i in range(100-cutoff):\n",
    "        predictions = torch.tensor(predict_single_sequence(result_tensor)).to(device).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        # print(f\"Predicted Value: {predictions}\")\n",
    "        result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
    "\n",
    "\n",
    "    results = result_tensor.squeeze(0).squeeze(-1).cpu()\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def plot_all(filename):\n",
    "\n",
    "    cutoff = 15\n",
    "\n",
    "    prior = lcpfn.sample_from_prior(np.random)\n",
    "    curve, _ = prior()\n",
    "    plt.plot(curve, \"black\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.arange(1, 101).unsqueeze(1)\n",
    "    y = torch.from_numpy(curve).float().unsqueeze(1)\n",
    "\n",
    "    model_lcpfn = lcpfn.LCPFN()\n",
    "    lcpfn_curve = model_lcpfn.predict_mean(x_train=x[:cutoff], y_train=y[:cutoff], x_test=x[cutoff: ])\n",
    "\n",
    "    big_model = torch.load('100_epochs.pth')\n",
    "    big_model_result = get_results(cutoff, y, big_model)\n",
    "\n",
    "    small_model = torch.load('small_model.pth')\n",
    "    small_model_result = get_results(cutoff, y, small_model)\n",
    "\n",
    "    small_model_no = torch.load('small_model_no_teaching.pth')\n",
    "    small_model_result_no = get_results(cutoff, y, small_model_no)\n",
    "\n",
    "    small_model_no_eu = torch.load('small_model_no_teaching_euclidean.pth')\n",
    "    small_model_result_no_eu = get_results(cutoff, y, small_model_no_eu)\n",
    "\n",
    "    plt.plot(curve, \"black\", label=\"Target\")\n",
    "    plt.plot(x[cutoff:], small_model_result[cutoff:], label=\"Small Model FT\")\n",
    "    plt.plot(x[cutoff:], small_model_result_no[cutoff:], label=\"Small Model\")\n",
    "    plt.plot(x[cutoff:], small_model_result_no_eu[cutoff:], label=\"Small Model EU\")\n",
    "    plt.plot(x[cutoff:], big_model_result[cutoff:], label=\"Large Model FT\")\n",
    "    plt.plot(x[cutoff:], lcpfn_curve, label=\"LCPFN\")\n",
    "\n",
    "    # plot cutoff\n",
    "    plt.vlines(cutoff + 1, 0, 1, linewidth=2, color=\"k\", label=\"Cutoff\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"graphs/{filename}.pdf\")\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.tensor(input_data, dtype=torch.float).to(device)\n",
      "C:\\Users\\remil\\AppData\\Local\\Temp\\ipykernel_1668\\3764918347.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result_tensor = torch.cat((result_tensor, torch.tensor(predictions)), dim=1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    plot_all(str(i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
