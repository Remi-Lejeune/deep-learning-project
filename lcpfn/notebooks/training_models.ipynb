{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of PyTorch models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build and train the 4 transformer models created using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd -q ..\n",
    "\n",
    "\n",
    "import lcpfn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Standard (sin/cos) positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode each point in input sequence into positional vectors that hold their positional information\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # turn input tokens into positional vecotrs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # calulate positional value for every element in vector\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to input tensor\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Euclidean positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode each point in input sequence into positional vectors that hold their positional information using euclidean distance\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # get x-value of each point (index)\n",
    "        position = torch.arange(max_len).unsqueeze(1).float()\n",
    "\n",
    "        #calculate euclidean distance\n",
    "        euclidean_distance = torch.sqrt(position ** 2)\n",
    "\n",
    "        # need to be in vector format for transformer to accept\n",
    "        pe = euclidean_distance.repeat(1, d_model)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to input tensor\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transformer model built using PyTorch Transformer module\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        # use the positional encoder defined above\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layers, num_layers=num_layers\n",
    "        )\n",
    "        self.encoder = nn.Linear(input_dim, model_dim)\n",
    "        self.decoder = nn.Linear(model_dim, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    # forwards pass\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.model_dim)\n",
    "\n",
    "        # encode input into positional vectors\n",
    "        src = self.pos_encoder(src)\n",
    "        src = self.dropout(src)\n",
    "\n",
    "        # src_mask = nn.Transformer.generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "        # output = self.transformer_encoder(src, src_mask)\n",
    "\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        # output only one prediction point (last)\n",
    "        output = output[:, -1, :]\n",
    "        return output.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# allow cuda support if GPU is present on device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Instantiate the large model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = TransformerModel(\n",
    "    input_dim=1,\n",
    "    model_dim=128,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dim_feedforward=512,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Instantiate the small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    input_dim=1,\n",
    "    model_dim=32,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    dim_feedforward=32,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_batch_func = lcpfn.create_get_batch_func(prior=lcpfn.sample_from_prior)\n",
    "# get a curce from their prior data\n",
    "# the x-values of the curve points are stored in X ([1..100]), the y-values are stored in Y\n",
    "X, Y, Y_noisy = get_batch_func(batch_size=1, seq_len=100, num_features=1)\n",
    "Y = Y.permute(1, 0) # permute because batch size was in dim 1\n",
    "\n",
    "dataset = TensorDataset(Y, Y)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "No Forced Teaching:\n",
    "\n",
    "The first 5 epochs are ran with forced teaching to give a reference point to the model\n",
    "\n",
    "Then for every of the remaining 95 epochs:\n",
    "\n",
    "- First 15 points are predicted with forced treaching (before cutoff). So model knows what curve to predict (otherwise would be just predicted points)\n",
    "    \n",
    "- Remaining 85 points are predicted without forced training (after cutoff). The prediction is added to the input of the model when predicting the next point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07294952124357224\n",
      "Epoch 1, Loss: 0.12479734420776367\n",
      "Epoch 2, Loss: 0.137273371219635\n",
      "Epoch 3, Loss: 0.07458188384771347\n",
      "Epoch 4, Loss: 0.13763538002967834\n",
      "Epoch 5, Loss: 0.32834605314577914\n",
      "Epoch 6, Loss: 0.08655254443011628\n",
      "Epoch 7, Loss: 0.07276828444535965\n",
      "Epoch 8, Loss: 0.06043922241916988\n",
      "Epoch 9, Loss: 0.06990627178373643\n",
      "Epoch 10, Loss: 0.07276537762379576\n",
      "Epoch 11, Loss: 0.07949924768594485\n",
      "Epoch 12, Loss: 0.06096301249914404\n",
      "Epoch 13, Loss: 0.06353910553127484\n",
      "Epoch 14, Loss: 0.08316188104530653\n",
      "Epoch 15, Loss: 0.06655544537818514\n",
      "Epoch 16, Loss: 0.06975374672482104\n",
      "Epoch 17, Loss: 0.0794184916316567\n",
      "Epoch 18, Loss: 0.06724467207827445\n",
      "Epoch 19, Loss: 0.06402873078729954\n",
      "Epoch 20, Loss: 0.07056964406859834\n",
      "Epoch 21, Loss: 0.06080140176426596\n",
      "Epoch 22, Loss: 0.06095988152604548\n",
      "Epoch 23, Loss: 0.0630595552012494\n",
      "Epoch 24, Loss: 0.07092146430665025\n",
      "Epoch 25, Loss: 0.06935044517135225\n",
      "Epoch 26, Loss: 0.06033167481906876\n",
      "Epoch 27, Loss: 0.052580945930102985\n",
      "Epoch 28, Loss: 0.07282605908331252\n",
      "Epoch 29, Loss: 0.06585941078553503\n",
      "Epoch 30, Loss: 0.06333018988315375\n",
      "Epoch 31, Loss: 0.07305487981659553\n",
      "Epoch 32, Loss: 0.06640623772095378\n",
      "Epoch 33, Loss: 0.06598836183338364\n",
      "Epoch 34, Loss: 0.0649168517094516\n",
      "Epoch 35, Loss: 0.06388810068486972\n",
      "Epoch 36, Loss: 0.06278737241987642\n",
      "Epoch 37, Loss: 0.05917447074687893\n",
      "Epoch 38, Loss: 0.05880971624816311\n",
      "Epoch 39, Loss: 0.07232834083426098\n",
      "Epoch 40, Loss: 0.060207909932827874\n",
      "Epoch 41, Loss: 0.06248737085894618\n",
      "Epoch 42, Loss: 0.06511590675000889\n",
      "Epoch 43, Loss: 0.06461338958372309\n",
      "Epoch 44, Loss: 0.05553915638259799\n",
      "Epoch 45, Loss: 0.0651053207581711\n",
      "Epoch 46, Loss: 0.07260768334265322\n",
      "Epoch 47, Loss: 0.056693675591532156\n",
      "Epoch 48, Loss: 0.06840363925874726\n",
      "Epoch 49, Loss: 0.06114896878989384\n",
      "Epoch 50, Loss: 0.060423758208348\n",
      "Epoch 51, Loss: 0.0645042142328407\n",
      "Epoch 52, Loss: 0.06306361846060327\n",
      "Epoch 53, Loss: 0.06297842361218642\n",
      "Epoch 54, Loss: 0.06462061230536303\n",
      "Epoch 55, Loss: 0.058701160939926\n",
      "Epoch 56, Loss: 0.05924890188612153\n",
      "Epoch 57, Loss: 0.05791124786656621\n",
      "Epoch 58, Loss: 0.05845110415009458\n",
      "Epoch 59, Loss: 0.0604531203392753\n",
      "Epoch 60, Loss: 0.05803720883168495\n",
      "Epoch 61, Loss: 0.06240421215375136\n",
      "Epoch 62, Loss: 0.06261142800158481\n",
      "Epoch 63, Loss: 0.05842297950312059\n",
      "Epoch 64, Loss: 0.05341636312065079\n",
      "Epoch 65, Loss: 0.053262586181573646\n",
      "Epoch 66, Loss: 0.06402239207381655\n",
      "Epoch 67, Loss: 0.05869429088988909\n",
      "Epoch 68, Loss: 0.05778603821897832\n",
      "Epoch 69, Loss: 0.05401858001925319\n",
      "Epoch 70, Loss: 0.055188669187515416\n",
      "Epoch 71, Loss: 0.057379940525823514\n",
      "Epoch 72, Loss: 0.0615781915412299\n",
      "Epoch 73, Loss: 0.05665319655112455\n",
      "Epoch 74, Loss: 0.05793723598500833\n",
      "Epoch 75, Loss: 0.054998608814727845\n",
      "Epoch 76, Loss: 0.05585182689520707\n",
      "Epoch 77, Loss: 0.06012716186219391\n",
      "Epoch 78, Loss: 0.05727190192300213\n",
      "Epoch 79, Loss: 0.05398622365830752\n",
      "Epoch 80, Loss: 0.05416854701444335\n",
      "Epoch 81, Loss: 0.05468084513404392\n",
      "Epoch 82, Loss: 0.05517639826827958\n",
      "Epoch 83, Loss: 0.057685369377420415\n",
      "Epoch 84, Loss: 0.05498616593343458\n",
      "Epoch 85, Loss: 0.05796923401369014\n",
      "Epoch 86, Loss: 0.05547238639576335\n",
      "Epoch 87, Loss: 0.05618956010787857\n",
      "Epoch 88, Loss: 0.052715696199300055\n",
      "Epoch 89, Loss: 0.056409956871469547\n",
      "Epoch 90, Loss: 0.058597560097809254\n",
      "Epoch 91, Loss: 0.05540102364456878\n",
      "Epoch 92, Loss: 0.055107921734318666\n",
      "Epoch 93, Loss: 0.05567237281664461\n",
      "Epoch 94, Loss: 0.05617402296936902\n",
      "Epoch 95, Loss: 0.05523396843847572\n",
      "Epoch 96, Loss: 0.058582722519233243\n",
      "Epoch 97, Loss: 0.0538941298472837\n",
      "Epoch 98, Loss: 0.055013705388343936\n",
      "Epoch 99, Loss: 0.05223953740897258\n"
     ]
    }
   ],
   "source": [
    "# first 5 epochs are done with forced teaching \n",
    "for epoch in range(0, 5):\n",
    "    model.train()\n",
    "    # initialise loss\n",
    "    total_loss = 0\n",
    "    #  for every curve in batch\n",
    "    for input_sequence, target_sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # transfer to device (GPU if available)\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "\n",
    "        input_sequence = input_sequence.unsqueeze(-1)  # [batch_size, input_length, features]\n",
    "\n",
    "        step_loss = 0\n",
    "\n",
    "        # for every point in curve\n",
    "        for i in range(99):\n",
    "            \n",
    "            # points in sequence before point we want to predict\n",
    "            current_input = input_sequence[:,:i + 1]\n",
    "\n",
    "            # make prediction\n",
    "            prediction = model(current_input)\n",
    "\n",
    "            # calculate loss from prediction\n",
    "            loss = criterion(prediction, target_sequence[:, i + 1])\n",
    "            step_loss += loss\n",
    "\n",
    "\n",
    "        # update params based on loss\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += step_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(data_loader)}\")\n",
    "\n",
    "# epochs without forced teaching: \n",
    "# first 15 points still forced teaching\n",
    "for epoch in range(5, 100):\n",
    "    model.train()\n",
    "    # initialise loss\n",
    "    total_loss = 0\n",
    "    #  for every curve in batch\n",
    "    for input_sequence, target_sequence in data_loader:\n",
    "        # transfer to device (GPU if available)\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "        input_sequence = input_sequence.unsqueeze(-1)  # [batch_size, input_length, features]\n",
    "\n",
    "        current_input = input_sequence[:, :1]\n",
    "\n",
    "        # for every point in curve\n",
    "        for i in range(99):\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            if i < 15: # first 15 points use forced teaching\n",
    "                current_input = input_sequence[:, :i + 1]\n",
    "            else: # remaining 85 without forced teaching (uses previous predictions)\n",
    "                prediction = prediction.detach()\n",
    "                current_input = torch.cat((current_input, prediction.unsqueeze(-1).unsqueeze(-1)), dim=1)\n",
    "\n",
    "            # update params based on loss\n",
    "            prediction = model(current_input)\n",
    "            loss = criterion(prediction, target_sequence[:, i + 1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(data_loader)}\")\n",
    "\n",
    "# torch.save(model, 'small_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Forced Teaching: Give true target point values as input everytime we make model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07982659339904785\n",
      "Epoch 1, Loss: 0.047912146896123886\n",
      "Epoch 2, Loss: 0.07933411747217178\n",
      "Epoch 3, Loss: 0.0660719946026802\n",
      "Epoch 4, Loss: 0.045396190136671066\n",
      "Epoch 5, Loss: 0.059247951954603195\n",
      "Epoch 6, Loss: 0.060916077345609665\n",
      "Epoch 7, Loss: 0.04747267812490463\n",
      "Epoch 8, Loss: 0.0565451942384243\n",
      "Epoch 9, Loss: 0.051484573632478714\n",
      "Epoch 10, Loss: 0.04767507314682007\n",
      "Epoch 11, Loss: 0.05113532394170761\n",
      "Epoch 12, Loss: 0.052436549216508865\n",
      "Epoch 13, Loss: 0.04851679876446724\n",
      "Epoch 14, Loss: 0.04516364261507988\n",
      "Epoch 15, Loss: 0.05020304024219513\n",
      "Epoch 16, Loss: 0.04838121682405472\n",
      "Epoch 17, Loss: 0.046012599021196365\n",
      "Epoch 18, Loss: 0.047351472079753876\n",
      "Epoch 19, Loss: 0.05071686580777168\n",
      "Epoch 20, Loss: 0.048999276012182236\n",
      "Epoch 21, Loss: 0.04605140909552574\n",
      "Epoch 22, Loss: 0.047080788761377335\n",
      "Epoch 23, Loss: 0.048482805490493774\n",
      "Epoch 24, Loss: 0.048989132046699524\n",
      "Epoch 25, Loss: 0.047332484275102615\n",
      "Epoch 26, Loss: 0.046500030905008316\n",
      "Epoch 27, Loss: 0.04660132899880409\n",
      "Epoch 28, Loss: 0.04620344564318657\n",
      "Epoch 29, Loss: 0.045161161571741104\n",
      "Epoch 30, Loss: 0.04584731534123421\n",
      "Epoch 31, Loss: 0.045611847192049026\n",
      "Epoch 32, Loss: 0.04753858968615532\n",
      "Epoch 33, Loss: 0.0451679565012455\n",
      "Epoch 34, Loss: 0.04470936208963394\n",
      "Epoch 35, Loss: 0.04624684154987335\n",
      "Epoch 36, Loss: 0.04633292555809021\n",
      "Epoch 37, Loss: 0.04676620289683342\n",
      "Epoch 38, Loss: 0.04718560352921486\n",
      "Epoch 39, Loss: 0.047435835003852844\n",
      "Epoch 40, Loss: 0.046398669481277466\n",
      "Epoch 41, Loss: 0.04639912396669388\n",
      "Epoch 42, Loss: 0.04541365057229996\n",
      "Epoch 43, Loss: 0.044598277658224106\n",
      "Epoch 44, Loss: 0.04670390859246254\n",
      "Epoch 45, Loss: 0.046523697674274445\n",
      "Epoch 46, Loss: 0.04801120236515999\n",
      "Epoch 47, Loss: 0.04568255692720413\n",
      "Epoch 48, Loss: 0.04615780711174011\n",
      "Epoch 49, Loss: 0.04543713852763176\n",
      "Epoch 50, Loss: 0.043361589312553406\n",
      "Epoch 51, Loss: 0.045182887464761734\n",
      "Epoch 52, Loss: 0.04467296227812767\n",
      "Epoch 53, Loss: 0.043471015989780426\n",
      "Epoch 54, Loss: 0.04454894736409187\n",
      "Epoch 55, Loss: 0.04680958762764931\n",
      "Epoch 56, Loss: 0.045877743512392044\n",
      "Epoch 57, Loss: 0.045391131192445755\n",
      "Epoch 58, Loss: 0.04664989560842514\n",
      "Epoch 59, Loss: 0.04449974745512009\n",
      "Epoch 60, Loss: 0.046788960695266724\n",
      "Epoch 61, Loss: 0.045149318873882294\n",
      "Epoch 62, Loss: 0.04440103471279144\n",
      "Epoch 63, Loss: 0.046485546976327896\n",
      "Epoch 64, Loss: 0.0454259067773819\n",
      "Epoch 65, Loss: 0.045545127242803574\n",
      "Epoch 66, Loss: 0.04551905393600464\n",
      "Epoch 67, Loss: 0.04578113555908203\n",
      "Epoch 68, Loss: 0.046023428440093994\n",
      "Epoch 69, Loss: 0.04532715305685997\n",
      "Epoch 70, Loss: 0.04621491581201553\n",
      "Epoch 71, Loss: 0.0455290861427784\n",
      "Epoch 72, Loss: 0.046883516013622284\n",
      "Epoch 73, Loss: 0.04540606588125229\n",
      "Epoch 74, Loss: 0.04520802199840546\n",
      "Epoch 75, Loss: 0.04586908221244812\n",
      "Epoch 76, Loss: 0.0464351661503315\n",
      "Epoch 77, Loss: 0.04637594148516655\n",
      "Epoch 78, Loss: 0.045442596077919006\n",
      "Epoch 79, Loss: 0.04541965574026108\n",
      "Epoch 80, Loss: 0.046448253095149994\n",
      "Epoch 81, Loss: 0.04505426436662674\n",
      "Epoch 82, Loss: 0.045875631272792816\n",
      "Epoch 83, Loss: 0.044983748346567154\n",
      "Epoch 84, Loss: 0.04494023695588112\n",
      "Epoch 85, Loss: 0.045806024223566055\n",
      "Epoch 86, Loss: 0.04526744782924652\n",
      "Epoch 87, Loss: 0.044138409197330475\n",
      "Epoch 88, Loss: 0.04627751186490059\n",
      "Epoch 89, Loss: 0.04638445004820824\n",
      "Epoch 90, Loss: 0.044680312275886536\n",
      "Epoch 91, Loss: 0.04451562464237213\n",
      "Epoch 92, Loss: 0.046180326491594315\n",
      "Epoch 93, Loss: 0.04587166756391525\n",
      "Epoch 94, Loss: 0.047281913459300995\n",
      "Epoch 95, Loss: 0.04672485962510109\n",
      "Epoch 96, Loss: 0.04583192989230156\n",
      "Epoch 97, Loss: 0.04525769501924515\n",
      "Epoch 98, Loss: 0.04495876654982567\n",
      "Epoch 99, Loss: 0.04514449089765549\n"
     ]
    }
   ],
   "source": [
    "# train with forced teaching\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    # initialise loss\n",
    "    total_loss = 0\n",
    "    # for every curve in batch\n",
    "    for input_sequence, target_sequence in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # transfer to device (GPU if available)\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "\n",
    "        input_sequence = input_sequence.unsqueeze(-1)  # [batch_size, input_length, features]\n",
    "\n",
    "        step_loss = 0\n",
    "\n",
    "        # for every point in curve\n",
    "        for i in range(99):\n",
    "            \n",
    "            # points in sequence before point we want to predict\n",
    "            current_input = input_sequence[:,:i + 1]\n",
    "\n",
    "            # make prediction\n",
    "            prediction = model(current_input)\n",
    "\n",
    "            # calculate loss from prediction\n",
    "            loss = criterion(prediction, target_sequence[:, i + 1])\n",
    "            step_loss += loss\n",
    "\n",
    "\n",
    "        # update params based on loss\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += step_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(data_loader)}\")\n",
    "\n",
    "# torch.save(model, 'small_model_FT.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
